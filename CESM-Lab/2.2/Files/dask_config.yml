distributed:
  version: 2

  dashboard:
    link: /user/{JUPYTERHUB_USER}/proxy/{port}/status

  scheduler:
    idle-timeout: 3600s

# uncomment to force new worker pods after 2 hrs
#  worker:
#    lifetime:
#      duration: "2 hours"
#      stagger: "10 s"
#      restart: true

  admin:
    tick:
      limit: 5s

logging:
  distributed: warning
  bokeh: critical
  tornado: critical
  tornado.application: error

kubernetes:
  name: dask-{JUPYTERHUB_USER}-{uuid}
  worker-template:
    spec:
      serviceAccount: daskkubernetes
      restartPolicy: Never
      containers:
        - name: dask-worker
          image: ${JUPYTER_IMAGE_SPEC}
          args:
            - dask-worker
            - --nthreads
            - '2'
            - --no-dashboard
            - --memory-limit
            - 7GB
            - --death-timeout
            - '60'
          resources:
            limits:
              cpu: "1.75"
              memory: 7G
            requests:
              cpu: 1
              memory: 7G

# Specific to each hub
#gateway:
#  address: https://staging.hub.pangeo.io/services/dask-gateway/
#  proxy-address: tls://35.225.202.35:8786

labextension:
  factory:
    module: dask_gateway
    class: GatewayCluster
    args: []
    kwargs: {}
